{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMi3Ian6AiunlsRf7+ecKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiwenwangANU/pytorch_review/blob/main/05_pytorch_going_modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Turn notebook cell code into python script and run in command line"
      ],
      "metadata": {
        "id": "SQvSVcd5vXpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/get_data.py\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "def data_download(\n",
        "    data_path: str,\n",
        "    request_url: str):\n",
        "  \"\"\"\n",
        "  Download data in zip file from remote url.\n",
        "  If the data download is successful, you should be able to access the pizza_steak_sushi images from the data directory.\n",
        "  Args:\n",
        "    data_path: Path to data local folder\n",
        "    request_url: Url for data file to get using get request\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  # Setup path to data folder\n",
        "  image_path = os.path.join(data_path, 'pizza_steak_sushi')\n",
        "\n",
        "  # If the image folder doesn't exist, download it and prepare it...\n",
        "  if os.path.exists(image_path):\n",
        "      print(f\"{image_path} directory exists.\")\n",
        "  else:\n",
        "      print(f\"Did not find {image_path} directory, creating one...\")\n",
        "      os.makedirs(image_path, exist_ok=True)\n",
        "\n",
        "  # Download pizza, steak, sushi data\n",
        "  with open(os.path.join(data_path, \"pizza_steak_sushi.zip\"), \"wb\") as f:\n",
        "      request = requests.get(request_url)\n",
        "      print(\"Downloading pizza, steak, sushi data...\")\n",
        "      f.write(request.content)\n",
        "\n",
        "  # Unzip pizza, steak, sushi data\n",
        "  with zipfile.ZipFile(os.path.join(data_path, \"pizza_steak_sushi.zip\"), \"r\") as zip_ref:\n",
        "      print(\"Unzipping pizza, steak, sushi data...\")\n",
        "      zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44BLDxXBxLcc",
        "outputId": "62887594-9ad3-41b8-c5ca-b4d8957befbc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/get_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    batch_size: int,\n",
        "    num_workers: int = NUM_WORKERS\n",
        "):\n",
        "  \"\"\"\n",
        "  Create training and testing dataloader\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader.\n",
        "  Returns:\n",
        "    a tuple of (train_loader, test_loader, classnames)\n",
        "    Where class_names is a list of the target classes.\n",
        "  \"\"\"\n",
        "  train_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "    ])\n",
        "\n",
        "  # Write transform for image\n",
        "  test_transform = transforms.Compose([\n",
        "      # Resize the images to 64x64\n",
        "      transforms.Resize(size=(64, 64)),\n",
        "      # Turn the image into a torch.Tensor\n",
        "      transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "  ])\n",
        "  train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
        "                                    transform=train_transform) # transforms to perform on data (images)\n",
        "  test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                  transform=test_transform)\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_data,\n",
        "                            batch_size=batch_size, # how many samples per batch?\n",
        "                            num_workers=num_workers, # how many subprocesses to use for data loading? (higher = more)\n",
        "                            shuffle=True, # shuffle the data?\n",
        "                            pin_memory=True) # faster training at cost of more memory\n",
        "  test_loader = DataLoader(dataset=test_data,\n",
        "                          batch_size=batch_size,\n",
        "                          num_workers=num_workers,\n",
        "                          pin_memory=True) # don't usually need to shuffle testing data\n",
        "\n",
        "  return train_loader, test_loader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRJV95LwxVWq",
        "outputId": "41480b0a-7eaf-455a-897f-b2e105ce4ddc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"\n",
        "    Model architecture copying TinyVGG from:\n",
        "    https://poloclub.github.io/cnn-explainer/\n",
        "    Args:\n",
        "      input_shape: An integer indicating number of input channels.\n",
        "      hidden_units: An integer indicating number of hidden units between layers.\n",
        "      output_shape: An integer indicating number of output units.\n",
        "    Returns:\n",
        "      tinyVGG model\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3, # how big is the square that's going over the image?\n",
        "                      stride=1, # default\n",
        "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,\n",
        "                         stride=2) # default stride value is same as kernel_size\n",
        "        )\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            # Where did this in_features shape come from?\n",
        "            # It's because each layer of our network compresses and changes the shape of our input data.\n",
        "            nn.Linear(in_features=hidden_units*16*16,\n",
        "                      out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.conv_block_1(x)\n",
        "        # print(x.shape)\n",
        "        x = self.conv_block_2(x)\n",
        "        # print(x.shape)\n",
        "        x = self.classifier(x)\n",
        "        # print(x.shape)\n",
        "        return x\n",
        "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuD9PuLS8tdX",
        "outputId": "5fd20c73-0447-4de0-f425-d1b57a168abe"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/engine.py\n",
        "\"\"\"\n",
        "Contains functions for training and testing a PyTorch model.\n",
        "\"\"\"\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  \"\"\"\n",
        "  Performs a single training step (one epoch) for a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The PyTorch model to be trained.\n",
        "        dataloader (torch.utils.data.DataLoader): Dataloader providing the training data in batches.\n",
        "        loss_fn (torch.nn.Module): Loss function used to compute the error between predictions and true labels.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer used to update model parameters.\n",
        "        device (torch.device): Device used to train/evel the model.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_loss, train_acc)\n",
        "            - train_loss (float): The average loss across all training batches.\n",
        "            - train_acc (float): The average accuracy across all training batches.\n",
        "  \"\"\"\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through data loader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      # Send data to target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # 2. Calculate  and accumulate loss\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate accuracy metrics across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "      # Loop through DataLoader batches\n",
        "      for batch, (X, y) in enumerate(dataloader):\n",
        "          # Send data to target device\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          # 1. Forward pass\n",
        "          test_pred_logits = model(X)\n",
        "\n",
        "          # 2. Calculate and accumulate loss\n",
        "          loss = loss_fn(test_pred_logits, y)\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          # Calculate and accumulate accuracy\n",
        "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "\n",
        "\n",
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          device: torch.device,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "\n",
        "  # 2. Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "      \"train_acc\": [],\n",
        "      \"test_loss\": [],\n",
        "      \"test_acc\": []\n",
        "  }\n",
        "\n",
        "  # 3. Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "      train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "      test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "      # 4. Print out what's happening\n",
        "      print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "      )\n",
        "\n",
        "      # 5. Update results dictionary\n",
        "      # Ensure all data is moved to CPU and converted to float for storage\n",
        "      results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
        "      results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
        "      results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
        "      results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
        "\n",
        "  # 6. Return the filled results at the end of the epochs\n",
        "  return results"
      ],
      "metadata": {
        "id": "6KufjiYqF6Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df748289-984c-4957-f59c-e2af6d5fa203"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "from going_modular import engine\n",
        "\n",
        "importlib.reload(engine)  # Forces reloading of the module"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeA14r6CRBhP",
        "outputId": "a9beece6-867f-45d3-eb55-423e719b8af3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'going_modular.engine' from '/content/going_modular/engine.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train.py\n",
        "\"\"\"\n",
        "Trains a PyTorch image classification model using device-agnostic code.\n",
        "\"\"\"\n",
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import get_data, data_setup, model_builder, engine\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Train a PyTorch image classification model.\")\n",
        "\n",
        "parser.add_argument(\"--batch_size\", type=int, default=16, help=\"Batch size for training.\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate for the optimizer.\")\n",
        "parser.add_argument(\"--num_epochs\", type=int, default=10, help=\"Number of training epochs.\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if(not os.path.exists('going_modular')):\n",
        "  os.makedirs('going_modular')\n",
        "\n",
        "get_data.data_download(data_path='data', request_url=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "\n",
        "train_loader, test_loader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir = 'data/pizza_steak_sushi/train',\n",
        "    test_dir = 'data/pizza_steak_sushi/test',\n",
        "    batch_size = args.batch_size\n",
        ")\n",
        "\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape=3, # number of color channels (3 for RGB)\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)).to(device)\n",
        "\n",
        "# Use train() by calling it from engine.py\n",
        "engine.train(model=model,\n",
        "             train_dataloader=train_loader,\n",
        "             test_dataloader=test_loader,\n",
        "             optimizer=torch.optim.Adam(params=model.parameters(), lr=args.lr),\n",
        "             device=device,\n",
        "             epochs=args.num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fq0_sy_MteG",
        "outputId": "4d6916a8-acee-4865-d753-484d623090a5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model on the command line\n",
        "!python going_modular/train.py  --batch_size 16 --lr 0.0001 --num_epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj67D7JUX5VS",
        "outputId": "ad01de98-e747-4e37-c76b-9e5ce7094e9b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists.\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n",
            "  0% 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.0985 | train_acc: 0.3083 | test_loss: 1.1019 | test_acc: 0.1875\n",
            " 20% 1/5 [00:01<00:07,  1.87s/it]Epoch: 2 | train_loss: 1.0977 | train_acc: 0.3250 | test_loss: 1.1032 | test_acc: 0.2375\n",
            " 40% 2/5 [00:04<00:07,  2.43s/it]Epoch: 3 | train_loss: 1.0995 | train_acc: 0.3500 | test_loss: 1.1038 | test_acc: 0.3250\n",
            " 60% 3/5 [00:06<00:04,  2.34s/it]Epoch: 4 | train_loss: 1.0990 | train_acc: 0.3250 | test_loss: 1.1014 | test_acc: 0.3125\n",
            " 80% 4/5 [00:08<00:02,  2.10s/it]Epoch: 5 | train_loss: 1.0964 | train_acc: 0.3875 | test_loss: 1.0979 | test_acc: 0.3125\n",
            "100% 5/5 [00:10<00:00,  2.09s/it]\n"
          ]
        }
      ]
    }
  ]
}